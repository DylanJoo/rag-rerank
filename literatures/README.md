# Literatures
---

---
## Terminology
- Improving effectiveness 
    - [W1] When-to-retrieve
    - [W2] What-to-retrieve
    - [E]  Error-handling

- Improve efficiency
    - [C] Context compression

---
### Application studies
- Recomp: improving retrieval-augmented lms with compression and selective augmentation
    * [https://arxiv.org/pdf/2310.04408](https://arxiv.org/pdf/2310.04408)

- Retrieval meets long context large language models
    * [https://arxiv.org/pdf/2310.03025](https://arxiv.org/pdf/2310.03025)

- Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions
    * [https://arxiv.org/pdf/2212.10509](https://arxiv.org/pdf/2212.10509)

- When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively
    * [https://arxiv.org/pdf/2404.19705](https://arxiv.org/pdf/2404.19705)

- Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models
    * [https://arxiv.org/pdf/2402.14207v1](https://arxiv.org/pdf/2402.14207v1)
- Quark: Controllable Text Generation with Reinforced [Un]learning
    * [https://openreview.net/pdf?id=5HaIds3ux5O](https://openreview.net/pdf?id=5HaIds3ux5O)

- In-Context Retrieval-Augmented Language Models
    * [https://arxiv.org/pdf/2302.00083](https://arxiv.org/pdf/2302.00083)

- SAIL: Search-Augmented Instruction Learning
    * [https://arxiv.org/pdf/2305.15225](https://arxiv.org/pdf/2305.15225)

- Atlas: Few-shot Learning with Retrieval Augmented Language Models
    * [https://arxiv.org/pdf/2208.03299](https://arxiv.org/pdf/2208.03299)

- Active Retrieval Augmented Generation
    * [https://arxiv.org/pdf/2305.06983](https://arxiv.org/pdf/2305.06983)

- Enabling Large Language Models to Generate Text with Citations
    * [https://arxiv.org/pdf/2305.14627](https://arxiv.org/pdf/2305.14627)

- RA-DIT: Retrieval-Augmented Dual Instruction Tuning
    * [https://arxiv.org/abs/2310.01352](https://arxiv.org/abs/2310.01352)

- Making retrieval-augmented language models robust to irrelevant context
    * [https://arxiv.org/pdf/2310.01558](https://arxiv.org/pdf/2310.01558)

- Self-Evaluation Guided Beam Search for Reasoning
    * [https://arxiv.org/pdf/2305.00633](https://arxiv.org/pdf/2305.00633)

- Self-consistency improves chain of thought reasoning in language models
    * [https://openreview.net/pdf?id=1PL1NIMMrw](https://openreview.net/pdf?id=1PL1NIMMrw)

- Language Models (Mostly) Know What They Know
    * [https://arxiv.org/pdf/2207.05221](https://arxiv.org/pdf/2207.05221)

- Evaluating Verifiability in Generative Search Engines
    * [https://arxiv.org/pdf/2304.09848](https://arxiv.org/pdf/2304.09848)

- FACTSCORE: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation
    * [https://arxiv.org/pdf/2305.14251](https://arxiv.org/pdf/2305.14251)

- RARR: Researching and Revising What Language Models Say, Using Language Models
    * [https://arxiv.org/pdf/2210.08726](https://arxiv.org/pdf/2210.08726)

- Enabling Large Language Models to Generate Text with Citations
    * [https://arxiv.org/pdf/2305.14627](https://arxiv.org/pdf/2305.14627)

- Toolformer: Language Models Can Teach Themselves to Use Tools
    * [https://arxiv.org/pdf/2302.04761](https://arxiv.org/pdf/2302.04761)

- Chain-of-verification reduces hallucination in large language models
    * [https://arxiv.org/pdf/2309.11495](https://arxiv.org/pdf/2309.11495)

- React: synergizing reasoning and acting in language models
    * [https://openreview.net/pdf?id=WE_vluYUL-X](https://openreview.net/pdf?id=WE_vluYUL-X)

---
### (might) Out-of-context studies
- Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models
    * [https://arxiv.org/abs/2310.04406](https://arxiv.org/abs/2310.04406)
---
### Theoretical and earlier studies
1. Training language models to follow instructions with human feedback [Ouyang et al., 2022](https://openreview.net/pdf?id=TG8KACxEON)
2. RAG for knowledge-intensitve tasks [Lewis et al., 2020](https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf)
3. Large Language Models Can Be Easily Distracted by Irrelevant Context [Shi et al., 2023](https://proceedings.mlr.press/v202/shi23a/shi23a.pdf)
4. Fine-Grained Human Feedback Gives Better Rewards for Language Model Training [Wu et al., 2023](https://arxiv.org/pdf/2306.01693) 
5. 

### Empirical studies
1. 


